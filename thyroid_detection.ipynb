{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c6fd9cd-9e43-4d8d-9976-a809dd5c6117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd#import the pandas module becuase our dataset is a csv file\n",
    "import numpy as np #import the numpy module becuase our dataset is a csv file\n",
    "import matplotlib.pyplot as plt#import the matplot library to plot the heatmap to see the correlation\n",
    "import seaborn as sns#import the seaborn library to plot the heatmap to see the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a636fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the correct fcols list, specify no header, and replace '?' with NaN.\n",
    "fcols = [\n",
    "    \"age\", \"sex\", \"on_thyroxine\", \"query_on_thyroxine\", \"on_antithyroid_medication\",\n",
    "    \"sick\", \"pregnant\", \"thyroid_surgery\", \"I131_treatment\", \"query_hypothyroid\",\n",
    "    \"query_hyperthyroid\", \"lithium\", \"goitre\", \"tumor\", \"hypopituitary\", \"psych\",\n",
    "    \"TSH measured\", \"TSH\", \"T3_measured\", \"T3\", \"TT4_measured\", \"TT4\",\n",
    "    \"T4U_measured\", \"T4U\", \"FTI_measured\", \"FTI\", \"TBG_measured\", \"TBG\", \"target\", \"source_id\" # source_id for the extra column\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9daffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- REPLACEMENT FOR CELL 3 ---\n",
    "# This line correctly reads the file, applies the names from Cell 2, \n",
    "# specifies no header (header=None), and replaces '?' with NaN.\n",
    "\n",
    "dataframe = pd.read_csv(\"thyroid.csv\", header=None, names=fcols, na_values=['?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe2a0dd5-0a19-4964-ac60-067f21ce671c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>on_thyroxine</th>\n",
       "      <th>query_on_thyroxine</th>\n",
       "      <th>on_antithyroid_medication</th>\n",
       "      <th>sick</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>thyroid_surgery</th>\n",
       "      <th>I131_treatment</th>\n",
       "      <th>query_hypothyroid</th>\n",
       "      <th>...</th>\n",
       "      <th>TT4_measured</th>\n",
       "      <th>TT4</th>\n",
       "      <th>T4U_measured</th>\n",
       "      <th>T4U</th>\n",
       "      <th>FTI_measured</th>\n",
       "      <th>FTI</th>\n",
       "      <th>TBG_measured</th>\n",
       "      <th>TBG</th>\n",
       "      <th>target</th>\n",
       "      <th>source_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>-[840801013]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>t</td>\n",
       "      <td>128.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>-[840801014]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>11.0</td>\n",
       "      <td>other</td>\n",
       "      <td>-[840801042]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>26.0</td>\n",
       "      <td>other</td>\n",
       "      <td>-[840803046]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>36.0</td>\n",
       "      <td>other</td>\n",
       "      <td>S[840803047]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9167</th>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>t</td>\n",
       "      <td>64.0</td>\n",
       "      <td>t</td>\n",
       "      <td>0.83</td>\n",
       "      <td>t</td>\n",
       "      <td>77.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SVI</td>\n",
       "      <td>-[870119022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9168</th>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>t</td>\n",
       "      <td>91.0</td>\n",
       "      <td>t</td>\n",
       "      <td>0.92</td>\n",
       "      <td>t</td>\n",
       "      <td>99.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SVI</td>\n",
       "      <td>-[870119023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9169</th>\n",
       "      <td>69</td>\n",
       "      <td>M</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>t</td>\n",
       "      <td>113.0</td>\n",
       "      <td>t</td>\n",
       "      <td>1.27</td>\n",
       "      <td>t</td>\n",
       "      <td>89.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SVI</td>\n",
       "      <td>I[870119025]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9170</th>\n",
       "      <td>47</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>t</td>\n",
       "      <td>75.0</td>\n",
       "      <td>t</td>\n",
       "      <td>0.85</td>\n",
       "      <td>t</td>\n",
       "      <td>88.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>-[870119027]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171</th>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>t</td>\n",
       "      <td>66.0</td>\n",
       "      <td>t</td>\n",
       "      <td>1.02</td>\n",
       "      <td>t</td>\n",
       "      <td>65.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>-[870119035]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9172 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age sex on_thyroxine query_on_thyroxine on_antithyroid_medication sick  \\\n",
       "0      29   F            f                  f                         f    f   \n",
       "1      29   F            f                  f                         f    f   \n",
       "2      41   F            f                  f                         f    f   \n",
       "3      36   F            f                  f                         f    f   \n",
       "4      32   F            f                  f                         f    f   \n",
       "...   ...  ..          ...                ...                       ...  ...   \n",
       "9167   56   M            f                  f                         f    f   \n",
       "9168   22   M            f                  f                         f    f   \n",
       "9169   69   M            f                  f                         f    f   \n",
       "9170   47   F            f                  f                         f    f   \n",
       "9171   31   M            f                  f                         f    f   \n",
       "\n",
       "     pregnant thyroid_surgery I131_treatment query_hypothyroid  ...  \\\n",
       "0           f               f              f                 t  ...   \n",
       "1           f               f              f                 f  ...   \n",
       "2           f               f              f                 f  ...   \n",
       "3           f               f              f                 f  ...   \n",
       "4           f               f              f                 f  ...   \n",
       "...       ...             ...            ...               ...  ...   \n",
       "9167        f               f              f                 f  ...   \n",
       "9168        f               f              f                 f  ...   \n",
       "9169        f               f              f                 f  ...   \n",
       "9170        f               f              f                 f  ...   \n",
       "9171        f               f              f                 t  ...   \n",
       "\n",
       "     TT4_measured    TT4 T4U_measured   T4U FTI_measured   FTI TBG_measured  \\\n",
       "0               f    NaN            f   NaN            f   NaN            f   \n",
       "1               t  128.0            f   NaN            f   NaN            f   \n",
       "2               f    NaN            f   NaN            f   NaN            t   \n",
       "3               f    NaN            f   NaN            f   NaN            t   \n",
       "4               f    NaN            f   NaN            f   NaN            t   \n",
       "...           ...    ...          ...   ...          ...   ...          ...   \n",
       "9167            t   64.0            t  0.83            t  77.0            f   \n",
       "9168            t   91.0            t  0.92            t  99.0            f   \n",
       "9169            t  113.0            t  1.27            t  89.0            f   \n",
       "9170            t   75.0            t  0.85            t  88.0            f   \n",
       "9171            t   66.0            t  1.02            t  65.0            f   \n",
       "\n",
       "       TBG target     source_id  \n",
       "0      NaN  other  -[840801013]  \n",
       "1      NaN  other  -[840801014]  \n",
       "2     11.0  other  -[840801042]  \n",
       "3     26.0  other  -[840803046]  \n",
       "4     36.0  other  S[840803047]  \n",
       "...    ...    ...           ...  \n",
       "9167   NaN    SVI  -[870119022]  \n",
       "9168   NaN    SVI  -[870119023]  \n",
       "9169   NaN    SVI  I[870119025]  \n",
       "9170   NaN  other  -[870119027]  \n",
       "9171   NaN  other  -[870119035]  \n",
       "\n",
       "[9172 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe #here we are rpinting the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4448e9-9ad3-4749-9182-22a08021163d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['other'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdataframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mother\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#here we are dropping the 'other column' of the dataset as it is not much used\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:5588\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5442\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5449\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5450\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5451\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5452\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5453\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5586\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5588\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5590\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5594\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5595\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4807\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4806\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4807\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4810\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4849\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4847\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4849\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4850\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4852\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4853\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['other'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# --- FIX FOR CELL 5 ---\n",
    "dataframe.drop(\"source_id\",axis=1,inplace=True) # Dropping the correct column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5742db9a-d00b-4854-9fe5-ab884d782777",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcols = [\"age\",\n",
    "                \"sex\",\n",
    "                \"on_thyroxine\",\n",
    "                \"query_on_thyroxine\",\n",
    "                \"on_antithyroid_medication\",\n",
    "                \"sick\",\n",
    "                \"pregnant\",\n",
    "                \"thyroid_surgery\",\n",
    "                \"I131_treatment\",\n",
    "                \"query_hypothyroid\",\n",
    "                \"query_hyperthyroid\",\n",
    "                \"lithium\",\n",
    "                \"goitre\",\n",
    "                \"tumor\",\n",
    "                \"hypopituitary\",\n",
    "                \"psych\",\n",
    "                \"TSH measured\",\n",
    "                \"TSH\",\n",
    "                \"T3_measured\",\n",
    "                \"T3\",\n",
    "                \"TT4_measured\",\n",
    "                \"TT4\",\n",
    "                \"T4U_measured\",\n",
    "                \"T4U\",\n",
    "                \"FTI_measured\",\n",
    "                \"FTI\",\n",
    "                \"TBG_measured\",\n",
    "                \"TBG\",\n",
    "               \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a5557b-2e43-4aec-8eea-a43e257006a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe  #printing the dataset first 5 rows again to see the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985dbc4e-6bba-4b2a-b13d-f450211b8b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.target #here we are storing our target into a target variable\n",
    "create = target.str.split('([A-Za-z]+)', expand=True) #here we are trying to split the target into create\n",
    "create = create[1] #here we took the 1st data of the create becuase it is in a string format\n",
    "target = create.replace({None:'Z'}) #Z is no a type of thyroid disease\n",
    "df.target = target #storing the target into our target dataset column again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_clean = dataframe['target'].astype(str)\n",
    "target_clean = target_clean.str.split('([A-Za-z]+)', expand=True)[1]\n",
    "dataframe['target'] = target_clean.replace({None: 'Z'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = [\n",
    "    \"on_thyroxine\", \"query_on_thyroxine\", \"on_antithyroid_medication\", \n",
    "    \"sick\", \"pregnant\", \"thyroid_surgery\", \"I131_treatment\", \n",
    "    \"query_hypothyroid\", \"query_hyperthyroid\", \"lithium\", \"goitre\", \n",
    "    \"tumor\", \"hypopituitary\", \"psych\"\n",
    "]\n",
    "\n",
    "for col in binary_cols:\n",
    "    dataframe[col] = dataframe[col].replace({'t': 1, 'f': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a15fd3b-70d3-48b5-811d-dd18851baa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a484070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the list of binary columns that contain 't' and 'f'\n",
    "binary_cols = [\n",
    "    \"on_thyroxine\", \"query_on_thyroxine\", \"on_antithyroid_medication\", \n",
    "    \"sick\", \"pregnant\", \"thyroid_surgery\", \"I131_treatment\", \n",
    "    \"query_hypothyroid\", \"query_hyperthyroid\", \"lithium\", \"goitre\", \n",
    "    \"tumor\", \"hypopituitary\", \"psych\"\n",
    "]\n",
    "\n",
    "# Apply the numerical encoding (0 and 1)\n",
    "for col in binary_cols:\n",
    "    # Assuming your DataFrame is named 'df'\n",
    "    df[col] = df[col].replace({'t': 1, 'f': 0})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30505ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INSERT THIS CODE HERE: After Binary Encoding Fix, replacing your original Cell 10 ---\n",
    "\n",
    "# Encode sex and use MODE for imputation (Fix 2)\n",
    "dataframe.sex.replace({'F': 2, 'M': 1}, inplace=True) \n",
    "mode_val = dataframe.sex.mode()[0] \n",
    "dataframe.sex.fillna(mode_val, inplace=True) \n",
    "dataframe.sex = dataframe.sex.astype(int)\n",
    "\n",
    "# Drop Unnecessary Columns (Fix 3 - No TT4 drop, drop measured flags)\n",
    "measured_cols = [\n",
    "    'TSH measured', 'T3_measured', \n",
    "    'TT4_measured', 'T4U_measured', 'FTI_measured', 'TBG_measured'\n",
    "]\n",
    "dataframe.drop(measured_cols, axis=1, inplace=True)\n",
    "\n",
    "# Drop the 'TBG' value column as it has too many missing values (>95%)\n",
    "dataframe.drop('TBG', axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c066acef-a086-4011-afbc-3b44eecd1953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Standardize Missing Values\n",
    "# Note: We assume the binary encoding fix (t/f -> 1/0) was run *before* this cell.\n",
    "dataframe = df.replace(['?'], np.nan) \n",
    "\n",
    "# 2. FIX 1: Correct Sex Imputation (Mode instead of Mean)\n",
    "# Encode sex\n",
    "dataframe.sex.replace({'F': 2, 'M': 1}, inplace=True) \n",
    "\n",
    "# Calculate the MODE (most frequent value) for the sex column\n",
    "# This is the statistically correct method for imputing a categorical feature.\n",
    "mode_val = dataframe.sex.mode()[0] \n",
    "\n",
    "# Fill null values with the MODE\n",
    "dataframe.sex.fillna(mode_val, inplace=True) \n",
    "# Ensure sex is integer type after imputation\n",
    "dataframe.sex = dataframe.sex.astype(int)\n",
    "\n",
    "\n",
    "# 3. Drop Unnecessary Columns (Combined & Corrected Naming)\n",
    "# Remove all '_measured' flag columns. Note the space in 'T4U_measured '\n",
    "measured_cols = [\n",
    "    'TSH measured', 'T3_measured', \n",
    "    'TT4_measured', 'T4U_measured ', \n",
    "    'FTI_measured', 'TBG_measured '\n",
    "]\n",
    "dataframe.drop(measured_cols, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# 4. FIX 2: Correct TT4 Dropping and Fix DataFrame Inconsistency\n",
    "# The line 'df.drop('TT4', ...)' must be REMOVED from this cell.\n",
    "# The original logic dropped TT4, but later cells tried to impute it. \n",
    "# TT4 is a vital lab value and should be KEPT for the KNN Imputer (Cell 15).\n",
    "\n",
    "# FIX 3: TBG Exclusion (Replacing the TT4 drop)\n",
    "# TBG has >95% missing values, making it useless. Drop it here.\n",
    "# Note: TBG_measured was dropped in step 3. This drops the actual 'TBG' value column.\n",
    "# If you didn't drop TBG in Cell 15, you should drop it here:\n",
    "# dataframe.drop('TBG', axis=1, inplace=True) # Optional, can be dropped later too. \n",
    "\n",
    "\n",
    "# --- CONTINUE TO CELL 11 (Heatmap) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a080325-b3ed-47be-8835-5c1528273ae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe.isnull().sum() #checking if any null value is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8f3ec9-a7fe-4897-9bc3-1d62a4ace550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9966a71-7252-4296-822d-0b97f90aae46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6742745-ac78-4fa0-a04b-dd7cabaa1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer #importing the KNNInputer function from the sklearn.impute to fill the null values\n",
    "knnimp = KNNImputer(n_neighbors=3) #making an instance of the KNN Inputer with neighbors=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf5dac5-0cca-44b9-91c3-49fe25a4f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['TSH','T3','TT4','T4U','FTI'] #strogin the empty columns into the cols variables\n",
    "for i in cols:\n",
    "    dataframe[i] = knnimp.fit_transform(dataframe[[i]]) #here we are using the fit_transform function to fit the dataframe and filling the null values of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada0a16-04f3-45a5-9656-5cc71fd824be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe.isnull().sum() # now we can see there is no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f9ac0-0508-4771-8036-9362390215e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop('target',axis=1) #making our x dataset by dropping our target column\n",
    "y = df.target #storing our target column into y column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beec383-e79c-4d58-8075-c4c410d8cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f20d3a-9c27-475e-bd67-08d85f577183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20)) #plotting the heatmap of size 20 cross 20\n",
    "sns.heatmap(df2.corr(),annot=True) #plotting the heatmap of correlation using the seaborn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26efe75b-cb5f-4b5a-81a6-fbeea29ffa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #importing the train test split function from model selection of skelarn\n",
    "X_train,X_test,y_train,y_test = train_test_split(df2,y,test_size=0.33,random_state=42) #dividing the dataset into training and testing dataset\n",
    "\n",
    "# --- CODE TO INSERT IMMEDIATELY AFTER train_test_split IN CELL 60 ---\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Identify the numerical columns that need scaling.\n",
    "numerical_cols = ['age', 'TSH', 'T3', 'TT4', 'T4U', 'FTI']\n",
    "\n",
    "# Initialize the Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler ONLY on the training data.\n",
    "scaler.fit(X_train[numerical_cols])\n",
    "\n",
    "# Transform both the training and testing data.\n",
    "X_train[numerical_cols] = scaler.transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e764772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INSERT THIS CODE IMMEDIATELY AFTER train_test_split IN CELL 60 ---\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Identify the numerical columns that need scaling.\n",
    "# These are the columns with large, continuous ranges.\n",
    "numerical_cols = ['age', 'TSH', 'T3', 'TT4', 'T4U', 'FTI']\n",
    "\n",
    "# Initialize the Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 1. Fit the scaler ONLY on the training data.\n",
    "scaler.fit(X_train[numerical_cols])\n",
    "\n",
    "# 2. Transform both the training and testing data.\n",
    "# This prevents data leakage and standardizes the features (mean=0, std=1).\n",
    "X_train[numerical_cols] = scaler.transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "# --- NOW CONTINUE TO K-NN TRAINING (CELL 65) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68115fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train, X_test, y_train, y_test were just created by the line above.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# 1. Define numerical columns to be scaled\n",
    "# These are the lab results and age which have large, varying scales.\n",
    "numerical_cols = ['age', 'TSH', 'T3', 'TT4', 'T4U', 'FTI']\n",
    "\n",
    "# 2. Initialize the Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 3. Fit the scaler ONLY on the training data and transform both sets\n",
    "# This prevents data leakage and is essential for K-NN.\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "# --- NOW PROCEED TO THE NEXT CELL (Likely Decision Tree or K-NN training) ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed78aae5-545d-445a-affa-fd93c9cbc5a8",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae8d3db-7f4b-46c4-9f00-af382f4c0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score#importing the accuracy score from the sklearn metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f737753-122d-4374-a9bb-a230f189a12d",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134921a5-3224-4791-82e9-0903f8eaab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier #importing the descision tree classifier from the sklearn tree \n",
    "tree = DecisionTreeClassifier(max_depth=3) #making an instance the descision tree with maxdepth = 3 as passing the input\n",
    "clf = tree.fit(X_train,y_train) #here we are passing our training and the testing data to the tree and fitting it\n",
    "y_pred = clf.predict(X_test) #predicting the value by passing the x_test datset to the tree \n",
    "accuracy_score(y_pred,y_test)# here we are printing the accuracy score of the prediction and the testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0dc0ca-6486-46e7-b475-44741ed47b15",
   "metadata": {},
   "source": [
    "# K-NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac46398-a09b-46a7-9e31-7f9921ec4577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier #importing the k nearest classifier from the sklearn neighbors \n",
    "neigh = KNeighborsClassifier(n_neighbors=3) #making an instance the k nearest neighbors with neighbors = 3 as passing the input\n",
    "knnclf = neigh.fit(X_train,y_train) #here we are passing our training and the testing data to the tree and fitting it\n",
    "y_pred = knnclf.predict(X_test) #predicting the value by passing the x_test datset to the tree \n",
    "accuracy_score(y_pred,y_test)# here we are printing the accuracy score of the prediction and the testing data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
