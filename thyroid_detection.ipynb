{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6fd9cd-9e43-4d8d-9976-a809dd5c6117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd#import the pandas module becuase our dataset is a csv file\n",
    "import numpy as np #import the numpy module becuase our dataset is a csv file\n",
    "import matplotlib.pyplot as plt#import the matplot library to plot the heatmap to see the correlation\n",
    "import seaborn as sns#import the seaborn library to plot the heatmap to see the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a636fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the correct fcols list, specify no header, and replace '?' with NaN.\n",
    "fcols = [\n",
    "    \"age\", \"sex\", \"on_thyroxine\", \"query_on_thyroxine\", \"on_antithyroid_medication\",\n",
    "    \"sick\", \"pregnant\", \"thyroid_surgery\", \"I131_treatment\", \"query_hypothyroid\",\n",
    "    \"query_hyperthyroid\", \"lithium\", \"goitre\", \"tumor\", \"hypopituitary\", \"psych\",\n",
    "    \"TSH measured\", \"TSH\", \"T3_measured\", \"T3\", \"TT4_measured\", \"TT4\",\n",
    "    \"T4U_measured\", \"T4U\", \"FTI_measured\", \"FTI\", \"TBG_measured\", \"TBG\", \"target\", \"source_id\" # source_id for the extra column\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9daffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- REPLACEMENT FOR CELL 3 ---\n",
    "# This line correctly reads the file, applies the names from Cell 2, \n",
    "# specifies no header (header=None), and replaces '?' with NaN.\n",
    "\n",
    "dataframe = pd.read_csv(\"thyroid.csv\", header=None, names=fcols, na_values=['?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2a0dd5-0a19-4964-ac60-067f21ce671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe #here we are rpinting the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4448e9-9ad3-4749-9182-22a08021163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FIX FOR CELL 5 ---\n",
    "dataframe.drop(\"source_id\",axis=1,inplace=True) # Dropping the correct column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5742db9a-d00b-4854-9fe5-ab884d782777",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcols = [\"age\",\n",
    "                \"sex\",\n",
    "                \"on_thyroxine\",\n",
    "                \"query_on_thyroxine\",\n",
    "                \"on_antithyroid_medication\",\n",
    "                \"sick\",\n",
    "                \"pregnant\",\n",
    "                \"thyroid_surgery\",\n",
    "                \"I131_treatment\",\n",
    "                \"query_hypothyroid\",\n",
    "                \"query_hyperthyroid\",\n",
    "                \"lithium\",\n",
    "                \"goitre\",\n",
    "                \"tumor\",\n",
    "                \"hypopituitary\",\n",
    "                \"psych\",\n",
    "                \"TSH measured\",\n",
    "                \"TSH\",\n",
    "                \"T3_measured\",\n",
    "                \"T3\",\n",
    "                \"TT4_measured\",\n",
    "                \"TT4\",\n",
    "                \"T4U_measured\",\n",
    "                \"T4U\",\n",
    "                \"FTI_measured\",\n",
    "                \"FTI\",\n",
    "                \"TBG_measured\",\n",
    "                \"TBG\",\n",
    "               \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a5557b-2e43-4aec-8eea-a43e257006a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe  #printing the dataset first 5 rows again to see the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985dbc4e-6bba-4b2a-b13d-f450211b8b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.target #here we are storing our target into a target variable\n",
    "create = target.str.split('([A-Za-z]+)', expand=True) #here we are trying to split the target into create\n",
    "create = create[1] #here we took the 1st data of the create becuase it is in a string format\n",
    "target = create.replace({None:'Z'}) #Z is no a type of thyroid disease\n",
    "df.target = target #storing the target into our target dataset column again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_clean = dataframe['target'].astype(str)\n",
    "target_clean = target_clean.str.split('([A-Za-z]+)', expand=True)[1]\n",
    "dataframe['target'] = target_clean.replace({None: 'Z'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = [\n",
    "    \"on_thyroxine\", \"query_on_thyroxine\", \"on_antithyroid_medication\", \n",
    "    \"sick\", \"pregnant\", \"thyroid_surgery\", \"I131_treatment\", \n",
    "    \"query_hypothyroid\", \"query_hyperthyroid\", \"lithium\", \"goitre\", \n",
    "    \"tumor\", \"hypopituitary\", \"psych\"\n",
    "]\n",
    "\n",
    "for col in binary_cols:\n",
    "    dataframe[col] = dataframe[col].replace({'t': 1, 'f': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a15fd3b-70d3-48b5-811d-dd18851baa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX: Change 'df' to 'dataframe'\n",
    "dataframe.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a484070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the list of binary columns that contain 't' and 'f'\n",
    "binary_cols = [\n",
    "    \"on_thyroxine\", \"query_on_thyroxine\", \"on_antithyroid_medication\", \n",
    "    \"sick\", \"pregnant\", \"thyroid_surgery\", \"I131_treatment\", \n",
    "    \"query_hypothyroid\", \"query_hyperthyroid\", \"lithium\", \"goitre\", \n",
    "    \"tumor\", \"hypopituitary\", \"psych\"\n",
    "]\n",
    "\n",
    "# Apply the numerical encoding (0 and 1)\n",
    "for col in binary_cols:\n",
    "    # Assuming your DataFrame is named 'df'\n",
    "    df[col] = df[col].replace({'t': 1, 'f': 0})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30505ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INSERT THIS CODE HERE: After Binary Encoding Fix, replacing your original Cell 10 ---\n",
    "\n",
    "# Encode sex and use MODE for imputation (Fix 2)\n",
    "dataframe.sex.replace({'F': 2, 'M': 1}, inplace=True) \n",
    "mode_val = dataframe.sex.mode()[0] \n",
    "dataframe.sex.fillna(mode_val, inplace=True) \n",
    "dataframe.sex = dataframe.sex.astype(int)\n",
    "\n",
    "# Drop Unnecessary Columns (Fix 3 - No TT4 drop, drop measured flags)\n",
    "measured_cols = [\n",
    "    'TSH measured', 'T3_measured', \n",
    "    'TT4_measured', 'T4U_measured', 'FTI_measured', 'TBG_measured'\n",
    "]\n",
    "dataframe.drop(measured_cols, axis=1, inplace=True)\n",
    "\n",
    "# Drop the 'TBG' value column as it has too many missing values (>95%)\n",
    "dataframe.drop('TBG', axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c066acef-a086-4011-afbc-3b44eecd1953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Standardize Missing Values\n",
    "# The initial loading in Cell 3 already handled '?' to NaN.\n",
    "\n",
    "# 2. FIX 1: Correct Sex Imputation (Mode instead of Mean)\n",
    "# Encode sex\n",
    "dataframe['sex'] = dataframe['sex'].replace({'F': 2, 'M': 1})\n",
    "\n",
    "# Calculate the MODE (most frequent value) for the sex column\n",
    "# This is the statistically correct method for imputing a categorical feature.\n",
    "mode_val = dataframe['sex'].mode()[0]\n",
    "\n",
    "# Fill null values with the MODE\n",
    "dataframe['sex'] = dataframe['sex'].fillna(mode_val)\n",
    "# Ensure sex is integer type after imputation\n",
    "dataframe['sex'] = dataframe['sex'].astype(int)\n",
    "\n",
    "\n",
    "# 3. Drop Unnecessary Columns (Combined & Corrected Naming)\n",
    "# The 'measured' columns and the 'TBG' column were already dropped in cell '30505ecf'.\n",
    "# This section of code is therefore redundant and was causing the KeyError.\n",
    "# It has been removed to prevent re-attempting to drop non-existent columns.\n",
    "\n",
    "# --- CONTINUE TO CELL 11 (Heatmap) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a080325-b3ed-47be-8835-5c1528273ae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe.isnull().sum() #checking if any null value is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8f3ec9-a7fe-4897-9bc3-1d62a4ace550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9966a71-7252-4296-822d-0b97f90aae46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6742745-ac78-4fa0-a04b-dd7cabaa1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer #importing the KNNInputer function from the sklearn.impute to fill the null values\n",
    "knnimp = KNNImputer(n_neighbors=3) #making an instance of the KNN Inputer with neighbors=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf5dac5-0cca-44b9-91c3-49fe25a4f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['TSH','T3','TT4','T4U','FTI'] #strogin the empty columns into the cols variables\n",
    "for i in cols:\n",
    "    dataframe[i] = knnimp.fit_transform(dataframe[[i]]) #here we are using the fit_transform function to fit the dataframe and filling the null values of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada0a16-04f3-45a5-9656-5cc71fd824be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe.isnull().sum() # now we can see there is no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f9ac0-0508-4771-8036-9362390215e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop('target',axis=1) #making our x dataset by dropping our target column\n",
    "y = df.target #storing our target column into y column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beec383-e79c-4d58-8075-c4c410d8cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f20d3a-9c27-475e-bd67-08d85f577183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20)) #plotting the heatmap of size 20 cross 20\n",
    "sns.heatmap(df2.corr(),annot=True) #plotting the heatmap of correlation using the seaborn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26efe75b-cb5f-4b5a-81a6-fbeea29ffa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #importing the train test split function from model selection of skelarn\n",
    "X_train,X_test,y_train,y_test = train_test_split(df2,y,test_size=0.33,random_state=42) #dividing the dataset into training and testing dataset\n",
    "\n",
    "# --- CODE TO INSERT IMMEDIATELY AFTER train_test_split IN CELL 60 ---\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Identify the numerical columns that need scaling.\n",
    "numerical_cols = ['age', 'TSH', 'T3', 'TT4', 'T4U', 'FTI']\n",
    "\n",
    "# Initialize the Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler ONLY on the training data.\n",
    "scaler.fit(X_train[numerical_cols])\n",
    "\n",
    "# Transform both the training and testing data.\n",
    "X_train[numerical_cols] = scaler.transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e764772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INSERT THIS CODE IMMEDIATELY AFTER train_test_split IN CELL 60 ---\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Identify the numerical columns that need scaling.\n",
    "# These are the columns with large, continuous ranges.\n",
    "numerical_cols = ['age', 'TSH', 'T3', 'TT4', 'T4U', 'FTI']\n",
    "\n",
    "# Initialize the Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 1. Fit the scaler ONLY on the training data.\n",
    "scaler.fit(X_train[numerical_cols])\n",
    "\n",
    "# 2. Transform both the training and testing data.\n",
    "# This prevents data leakage and standardizes the features (mean=0, std=1).\n",
    "X_train[numerical_cols] = scaler.transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "# --- NOW CONTINUE TO K-NN TRAINING (CELL 65) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68115fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train, X_test, y_train, y_test were just created by the line above.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# 1. Define numerical columns to be scaled\n",
    "# These are the lab results and age which have large, varying scales.\n",
    "numerical_cols = ['age', 'TSH', 'T3', 'TT4', 'T4U', 'FTI']\n",
    "\n",
    "# 2. Initialize the Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 3. Fit the scaler ONLY on the training data and transform both sets\n",
    "# This prevents data leakage and is essential for K-NN.\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "# --- NOW PROCEED TO THE NEXT CELL (Likely Decision Tree or K-NN training) ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed78aae5-545d-445a-affa-fd93c9cbc5a8",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae8d3db-7f4b-46c4-9f00-af382f4c0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score#importing the accuracy score from the sklearn metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f737753-122d-4374-a9bb-a230f189a12d",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134921a5-3224-4791-82e9-0903f8eaab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier #importing the descision tree classifier from the sklearn tree \n",
    "tree = DecisionTreeClassifier(max_depth=3) #making an instance the descision tree with maxdepth = 3 as passing the input\n",
    "clf = tree.fit(X_train,y_train) #here we are passing our training and the testing data to the tree and fitting it\n",
    "y_pred = clf.predict(X_test) #predicting the value by passing the x_test datset to the tree \n",
    "accuracy_score(y_pred,y_test)# here we are printing the accuracy score of the prediction and the testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0dc0ca-6486-46e7-b475-44741ed47b15",
   "metadata": {},
   "source": [
    "# K-NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac46398-a09b-46a7-9e31-7f9921ec4577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier #importing the k nearest classifier from the sklearn neighbors \n",
    "neigh = KNeighborsClassifier(n_neighbors=3) #making an instance the k nearest neighbors with neighbors = 3 as passing the input\n",
    "knnclf = neigh.fit(X_train,y_train) #here we are passing our training and the testing data to the tree and fitting it\n",
    "y_pred = knnclf.predict(X_test) #predicting the value by passing the x_test datset to the tree \n",
    "accuracy_score(y_pred,y_test)# here we are printing the accuracy score of the prediction and the testing data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
